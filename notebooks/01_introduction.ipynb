{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction to Agentic AI\n",
        "\n",
        "Welcome! This notebook gives you a high-level map of what *agentic* behavior means for generative AI systems and how the rest of this curriculum builds on that idea. By the end you should be able to describe an agentic workflow, recognize the moving parts in a mock interaction, and know what the upcoming notebooks will cover."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is agentic behavior?\n",
        "\n",
        "Agentic behavior is when a generative model does more than emit a single response. Instead, it actively *decides what to do next* based on goals, observations, and available tools. A typical agent:\n",
        "\n",
        "1. **Perceives the situation** through user input or environmental signals.\n",
        "2. **Plans** a sequence of steps that could achieve the goal.\n",
        "3. **Acts** by invoking tools, APIs, or self-reflection loops.\n",
        "4. **Evaluates** the result to determine whether to continue or stop.\n",
        "\n",
        "This control loop is often called \"observe - plan - act - reflect\". In an agentic system, the model *uses* its generation capacity to manage that loop, effectively becoming the decision-maker that coordinates tools and data sources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why does this matter?\n",
        "\n",
        "Traditional prompting treats the model as a passive text generator. Agentic design lets us build assistants that can, for example, fetch documents, call external services, summarize intermediate findings, and explain their reasoning. The upcoming notebooks teach you how to scaffold those behaviors reliably:\n",
        "\n",
        "- **Notebook 02 \u2014 Function Calling Basics:** How to structure tool descriptions so the model can request them responsibly.\n",
        "- **Notebook 03 \u2014 Model Context Protocol (MCP):** How to package memories, documents, and tools into a context the model can actively navigate.\n",
        "- **Notebook 04 \u2014 Agent-to-Agent Protocol:** How to coordinate multiple agents that collaborate or critique one another.\n",
        "\n",
        "Keep these goals in mind as you work through the exercises below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mock transcripts of agentic reasoning\n",
        "\n",
        "The following snippets imitate what a large language model might emit while managing its own plan. They are intentionally compact so you can glance at the structure before diving deeper later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "research_assistant = {\n",
        "    \"role\": \"assistant\",\n",
        "    \"goal\": \"Summarize key points from two policy briefs.\",\n",
        "    \"state\": {\n",
        "        \"step\": 2,\n",
        "        \"notes\": [\n",
        "            \"Loaded brief A via `download_document`.\",\n",
        "            \"Need to compare emissions targets.\"\n",
        "        ]\n",
        "    },\n",
        "    \"next_action\": {\n",
        "        \"type\": \"tool_call\",\n",
        "        \"tool_name\": \"search_repository\",\n",
        "        \"arguments\": {\n",
        "            \"collection\": \"policy_briefs\",\n",
        "            \"query\": \"emissions target 2035\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(json.dumps(research_assistant, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpreting the transcript\n",
        "\n",
        "- The `goal` field captures the high-level objective the agent keeps referring back to.\n",
        "- The `state` section acts like short-term memory: it records previous steps and outstanding questions.\n",
        "- The `next_action` block shows the agent deciding to call a tool, including which arguments to pass.\n",
        "\n",
        "Notice how this resembles structured function documentation: each element communicates intent and context, not just raw text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customer_support = {\n",
        "    \"role\": \"assistant\",\n",
        "    \"goal\": \"Resolve a shipment delay for order #4821.\",\n",
        "    \"state\": {\n",
        "        \"step\": 1,\n",
        "        \"hypothesis\": \"Package stuck at customs.\",\n",
        "        \"evidence_needed\": [\n",
        "            \"Latest carrier scan\",\n",
        "            \"Customs documentation status\"\n",
        "        ]\n",
        "    },\n",
        "    \"next_action\": {\n",
        "        \"type\": \"reflection\",\n",
        "        \"prompt\": \"If customs is clear, what other bottlenecks should I check?\"\n",
        "    },\n",
        "    \"fallback_plan\": [\n",
        "        \"Escalate to human agent if no updates in 10 minutes.\",\n",
        "        \"Offer expedited replacement if package lost.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(json.dumps(customer_support, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Key takeaways from the mock examples\n",
        "\n",
        "1. **Structure communicates intent.** The model is not improvising blindly; it keeps structured notes.\n",
        "2. **Tool use is explicit.** When the agent wants external data, it encodes the tool name and arguments.\n",
        "3. **Reflection is part of the plan.** Agentic systems often pause to reassess before committing to a new action.\n",
        "\n",
        "The rest of this curriculum will show you how to produce, parse, and guide structures like these."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Practice: Concept check\n",
        "\n",
        "Try the quick quiz below. Edit the `selected_answers` dictionary so each question maps to your chosen option (for example, `'Q1': 'B'`). Then run the checking cell to see feedback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "quiz = {\n",
        "    \"Q1\": {\n",
        "        \"prompt\": \"Which statement best defines agentic behavior in generative AI?\",\n",
        "        \"options\": {\n",
        "            \"A\": \"Generating longer responses regardless of context.\",\n",
        "            \"B\": \"Looping through observe, plan, act, and reflect steps to pursue a goal.\",\n",
        "            \"C\": \"Using random sampling to produce creative ideas.\"\n",
        "        },\n",
        "        \"answer\": \"B\"\n",
        "    },\n",
        "    \"Q2\": {\n",
        "        \"prompt\": \"In the research assistant example, why does the agent store notes in its state?\",\n",
        "        \"options\": {\n",
        "            \"A\": \"To remember context and pending tasks across tool calls.\",\n",
        "            \"B\": \"To encrypt sensitive data.\",\n",
        "            \"C\": \"To shorten its responses.\"\n",
        "        },\n",
        "        \"answer\": \"A\"\n",
        "    },\n",
        "    \"Q3\": {\n",
        "        \"prompt\": \"When should an agent schedule a reflection step instead of another tool call?\",\n",
        "        \"options\": {\n",
        "            \"A\": \"When it needs to reassess hypotheses or decide between competing actions.\",\n",
        "            \"B\": \"Whenever a user asks a follow-up question.\",\n",
        "            \"C\": \"Only when a tool fails.\"\n",
        "        },\n",
        "        \"answer\": \"A\"\n",
        "    },\n",
        "}\n",
        "\n",
        "# Set your answers here before running the check.\n",
        "selected_answers = {\n",
        "    \"Q1\": None,\n",
        "    \"Q2\": None,\n",
        "    \"Q3\": None,\n",
        "}\n",
        "\n",
        "def check_answers(selections):\n",
        "    for key, item in quiz.items():\n",
        "        user_choice = selections.get(key)\n",
        "        correct = item[\"answer\"]\n",
        "        if user_choice is None:\n",
        "            print(f\"{key}: No answer selected yet.\")\n",
        "        elif user_choice == correct:\n",
        "            print(f\"{key}: \u2705 Correct \u2014 {item['options'][correct]}\")\n",
        "        else:\n",
        "            print(f\"{key}: \u274c Try again. You chose '{user_choice}' but '{correct}' is correct.\")\n",
        "\n",
        "check_answers(selected_answers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection prompt\n",
        "\n",
        "Take a minute to jot down (in your own words) the difference between a prompt-engineered response and an agent that coordinates tools. Consider: what information does each need, and how do you measure success?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps\n",
        "\n",
        "Proceed to the next notebook to learn how to describe tools so that an agentic model can request them accurately."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}